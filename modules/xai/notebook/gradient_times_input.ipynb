{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bumjin/anaconda3/envs/deeping/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Get the MNIST DATA\n",
      "[+] Finished loading data & Preprocessing\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as vision_dsets\n",
    "from torch.utils import data\n",
    "import torchvision.transforms as T # Transformation functions to manipulate images\n",
    "\n",
    "device = \"cuda\"\n",
    "# device = \"cpu\"\n",
    "\n",
    "def get_mnist_dataloader(root='untracked',train =True,transforms=T.ToTensor() ,download =True,batch_size = 32,num_worker = 1):\n",
    "    print (\"[+] Get the MNIST DATA\")\n",
    "    \"\"\"\n",
    "    We will use Mnist data for our tutorial \n",
    "    \"\"\"\n",
    "    mnist_train = vision_dsets.MNIST(root = root,  #root is the place to store your data. \n",
    "                                    train = True,  \n",
    "                                    transform = transforms,\n",
    "                                    download=download)\n",
    "    mnist_test = vision_dsets.MNIST(root = root,\n",
    "                                    train = False, \n",
    "                                    transform = transforms,\n",
    "                                    download=download)\n",
    "    \"\"\"\n",
    "    Data Loader is a iterator that fetches the data with the number of desired batch size. \n",
    "    * Practical Guide : What is the optimal batch size? \n",
    "      - Usually.., higher the batter. \n",
    "      - We recommend to use it as a multiple of 2 to efficiently utilize the gpu memory. (related to bit size)\n",
    "    \"\"\"\n",
    "    trainDataLoader = data.DataLoader(dataset = mnist_train,  # information about your data type\n",
    "                                      batch_size = batch_size, # batch size\n",
    "                                      shuffle =True, # Whether to shuffle your data for every epoch. (Very important for training performance)\n",
    "                                      num_workers = 1) # number of workers to load your data. (usually number of cpu cores)\n",
    "\n",
    "    testDataLoader = data.DataLoader(dataset = mnist_test, \n",
    "                                    batch_size = batch_size,\n",
    "                                    shuffle = False, # we don't actually need to shuffle data for test\n",
    "                                    num_workers = 1) #\n",
    "    print (\"[+] Finished loading data & Preprocessing\")\n",
    "    return trainDataLoader,testDataLoader\n",
    "\n",
    "trainDataLoader, testDataLoader = get_mnist_dataloader(transforms=T.Compose([T.ToTensor()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, model=\"linear\"):\n",
    "        super().__init__()\n",
    "        self.model_type = model\n",
    "        if model ==\"linear\":\n",
    "            self.linear1 = nn.Linear(784, 128)\n",
    "            self.linear2 = nn.Linear(128, 10)\n",
    "        elif model == \"cnn\":\n",
    "            self.conv1 = nn.Conv2d(in_channels= 1, out_channels=32, kernel_size=3, stride=1)\t\n",
    "            self.conv2 = nn.Conv2d(in_channels=32, out_channels=28, kernel_size=3, stride=2)\n",
    "            self.fc1 = nn.Linear(in_features=4032, out_features=512)\n",
    "            self.fc2 = nn.Linear(in_features=512, out_features=10)\n",
    "            \n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "\n",
    "        if self.model_type == \"linear\":\n",
    "            x = x.view(batch_size, -1)\n",
    "            x = self.linear1(x)\n",
    "            x = nn.functional.relu(x)\n",
    "            x = self.linear2(x) \n",
    "        else:\n",
    "\n",
    "            x = nn.functional.relu(self.conv1(x))\n",
    "            x = nn.functional.relu(self.conv2(x))\n",
    "            x = x.contiguous().view(batch_size, -1)\n",
    "            x = self.fc1(x)\n",
    "            x = nn.functional.relu(x)\n",
    "            x = self.fc2(x)\n",
    "        return x \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_model = Model(model=\"linear\").to(device=device)\n",
    "cnn_model = Model(model=\"cnn\").to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Training Started with model ---\n",
      "Model(\n",
      "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv2): Conv2d(32, 28, kernel_size=(3, 3), stride=(2, 2))\n",
      "  (fc1): Linear(in_features=4032, out_features=512, bias=True)\n",
      "  (fc2): Linear(in_features=512, out_features=10, bias=True)\n",
      ")\n",
      "[1,   500] loss: 0.286\n",
      "[1,  1000] loss: 0.102\n",
      "[1,  1500] loss: 0.075\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "def train(net, train_loader, optimizer, criterion,  epoch=2):\n",
    "    net.train()\n",
    "    for e in range(epoch):\n",
    "        running_loss = 0.0  \n",
    "        for i, data in enumerate(train_loader, 0): \n",
    "            # get the inputs\n",
    "            inputs, labels = data # Return type for data in dataloader is tuple of (input_data, labels)\n",
    "            inputs = Variable(inputs).to(device=device)\n",
    "            labels = Variable(labels).to(device=device)\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()    \n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = net(inputs) # get output after passing through the network\n",
    "            loss = criterion(outputs, labels) # compute model's score using the loss function \n",
    "            loss.backward() # perform back-propagation from the loss\n",
    "            optimizer.step() # perform gradient descent with given optimizer\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            if (i+1) % 500 == 0:    # print every 2000 mini-batches\n",
    "                print('[%d, %5d] loss: %.3f' % (e + 1, i + 1, running_loss / 500))\n",
    "                running_loss = 0.0\n",
    "\n",
    "criterion = nn.CrossEntropyLoss() \n",
    "models = [cnn_model]\n",
    "optimizers  = [torch.optim.Adam(cnn_model.parameters(), lr=0.001, )]\n",
    "\n",
    "\n",
    "for model, opti, in zip(models, optimizers):\n",
    "    print(\"--- Training Started with model ---\")\n",
    "    print(model)\n",
    "    train(model, trainDataLoader, opti, criterion, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "from src.gradient_times_input import gradient_times_input\n",
    "\n",
    "x = trainDataLoader.dataset[10][0].clone()\n",
    "model = models[0]\n",
    "\n",
    "grad = gradient_times_input(model, x , to=device)\n",
    "print(grad.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Only Tensors created explicitly by the user (graph leaves) support the deepcopy protocol at the moment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/data3/bumjin_store/playground/modules/xai/notebook/gradient_times_input.ipynb Cell 6'\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bhinton.kaist.ac.kr/data3/bumjin_store/playground/modules/xai/notebook/gradient_times_input.ipynb#ch0000005vscode-remote?line=7'>8</a>\u001b[0m input_attribution \u001b[39m=\u001b[39m input_attribution\u001b[39m.\u001b[39msum(\u001b[39m0\u001b[39m)\u001b[39m.\u001b[39msqueeze(\u001b[39m0\u001b[39m)\u001b[39m.\u001b[39mcpu()\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bhinton.kaist.ac.kr/data3/bumjin_store/playground/modules/xai/notebook/gradient_times_input.ipynb#ch0000005vscode-remote?line=8'>9</a>\u001b[0m ax[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mimshow(\u001b[39minput\u001b[39m, cmap\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mbinary\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bhinton.kaist.ac.kr/data3/bumjin_store/playground/modules/xai/notebook/gradient_times_input.ipynb#ch0000005vscode-remote?line=9'>10</a>\u001b[0m ax[\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mimshow(copy\u001b[39m.\u001b[39;49mdeepcopy(input_attribution), alpha\u001b[39m=\u001b[39m\u001b[39m0.5\u001b[39m, cmap\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mhot\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bhinton.kaist.ac.kr/data3/bumjin_store/playground/modules/xai/notebook/gradient_times_input.ipynb#ch0000005vscode-remote?line=10'>11</a>\u001b[0m ax[\u001b[39m2\u001b[39m]\u001b[39m.\u001b[39mimshow(\u001b[39minput\u001b[39m, cmap\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mbinary\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bhinton.kaist.ac.kr/data3/bumjin_store/playground/modules/xai/notebook/gradient_times_input.ipynb#ch0000005vscode-remote?line=11'>12</a>\u001b[0m ax[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mset_ylabel(name, fontsize\u001b[39m=\u001b[39m\u001b[39m20\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/deeping/lib/python3.8/copy.py:153\u001b[0m, in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    <a href='file:///home/bumjin/anaconda3/envs/deeping/lib/python3.8/copy.py?line=150'>151</a>\u001b[0m copier \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(x, \u001b[39m\"\u001b[39m\u001b[39m__deepcopy__\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    <a href='file:///home/bumjin/anaconda3/envs/deeping/lib/python3.8/copy.py?line=151'>152</a>\u001b[0m \u001b[39mif\u001b[39;00m copier \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///home/bumjin/anaconda3/envs/deeping/lib/python3.8/copy.py?line=152'>153</a>\u001b[0m     y \u001b[39m=\u001b[39m copier(memo)\n\u001b[1;32m    <a href='file:///home/bumjin/anaconda3/envs/deeping/lib/python3.8/copy.py?line=153'>154</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    <a href='file:///home/bumjin/anaconda3/envs/deeping/lib/python3.8/copy.py?line=154'>155</a>\u001b[0m     reductor \u001b[39m=\u001b[39m dispatch_table\u001b[39m.\u001b[39mget(\u001b[39mcls\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/deeping/lib/python3.8/site-packages/torch/_tensor.py:86\u001b[0m, in \u001b[0;36mTensor.__deepcopy__\u001b[0;34m(self, memo)\u001b[0m\n\u001b[1;32m     <a href='file:///home/bumjin/anaconda3/envs/deeping/lib/python3.8/site-packages/torch/_tensor.py?line=83'>84</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(Tensor\u001b[39m.\u001b[39m__deepcopy__, (\u001b[39mself\u001b[39m,), \u001b[39mself\u001b[39m, memo)\n\u001b[1;32m     <a href='file:///home/bumjin/anaconda3/envs/deeping/lib/python3.8/site-packages/torch/_tensor.py?line=84'>85</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mis_leaf:\n\u001b[0;32m---> <a href='file:///home/bumjin/anaconda3/envs/deeping/lib/python3.8/site-packages/torch/_tensor.py?line=85'>86</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mOnly Tensors created explicitly by the user \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     <a href='file:///home/bumjin/anaconda3/envs/deeping/lib/python3.8/site-packages/torch/_tensor.py?line=86'>87</a>\u001b[0m                        \u001b[39m\"\u001b[39m\u001b[39m(graph leaves) support the deepcopy protocol at the moment\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='file:///home/bumjin/anaconda3/envs/deeping/lib/python3.8/site-packages/torch/_tensor.py?line=87'>88</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mid\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39min\u001b[39;00m memo:\n\u001b[1;32m     <a href='file:///home/bumjin/anaconda3/envs/deeping/lib/python3.8/site-packages/torch/_tensor.py?line=88'>89</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m memo[\u001b[39mid\u001b[39m(\u001b[39mself\u001b[39m)]\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Only Tensors created explicitly by the user (graph leaves) support the deepcopy protocol at the moment"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x720 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import copy \n",
    "import matplotlib.pyplot as plt \n",
    "fig, ax = plt.subplots(1, 3, constrained_layout=True, figsize=(10,10))\n",
    "\n",
    "\n",
    "for i, (input_attribution, name) in enumerate(zip([grad], [\"sensitivity\"])):\n",
    "    input = x.detach().cpu().permute(1,2,0)\n",
    "    input_attribution = input_attribution.sum(0).squeeze(0).cpu()\n",
    "    ax[0].imshow(input, cmap='binary')\n",
    "    ax[1].imshow(copy.deepcopy(input_attribution), alpha=0.5, cmap='hot')\n",
    "    ax[2].imshow(input, cmap='binary')\n",
    "    ax[0].set_ylabel(name, fontsize=20)\n",
    "\n",
    "\n",
    "\n",
    "ax[0].set_title(\"original\")\n",
    "ax[1].set_title(\"gradient\")\n",
    "ax[2].set_title(\"overlay\")\n",
    "\n",
    "\n",
    "pcm1 = ax[2].pcolormesh(grad.sum(0).squeeze(0).cpu(), alpha=0.5, cmap='hot')\n",
    "cax = ax[2].inset_axes([1.05, 0.0, 0.2, 1.0], transform=ax[2].transAxes)\n",
    "fig.colorbar(pcm1, ax=ax[2], cax=cax)\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cbc4c7136b33e244a0926e55a8aa1e57f1c839903e331a380cefab98f3f0f979"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('deeping')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
