{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray \n",
    "import gym \n",
    "import numpy as np \n",
    "from gym.spaces import Box, Discrete\n",
    "from ray.rllib.env import MultiAgentEnv\n",
    "from ray.rllib.policy.policy import PolicySpec\n",
    "\n",
    "class CustomEnv(MultiAgentEnv, gym.Env):\n",
    "    def __init__(self, config):\n",
    "        pass\n",
    "        # do not require action spaces and observation spaces\n",
    "    \n",
    "    def _obs(self):\n",
    "        return {\n",
    "            \"state\": np.random.random(size=(2,3)),\n",
    "            \"otehrs\": np.random.random(size=(2,3))\n",
    "            }\n",
    "\n",
    "    def step(self, action_dict):\n",
    "        # done and reward must be dictionary for each agent \n",
    "        # observation doesn't have to be agent dictionary -> will be handled at observation function. \n",
    "        \n",
    "        done = {a:np.random.randint(2) for a in action_dict.keys()}\n",
    "        done[\"__all__\"] = True if (True in done.values()) else False     \n",
    "           \n",
    "        return self._obs(), {a:0 for a in action_dict.keys()}, done, {}\n",
    "    \n",
    "    def reset(self):\n",
    "        return self._obs()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-24 13:25:34 (running for 00:00:00.12)<br>Memory usage on this node: 15.0/16.0 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/8 CPUs, 0/0 GPUs, 0.0/8.59 GiB heap, 0.0/4.29 GiB objects<br>Result logdir: /Users/bumjin/ray_results/PPO<br>Number of trials: 1/1 (1 PENDING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name               </th><th>status  </th><th>loc  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CustomEnv_cf5ce_00000</td><td>PENDING </td><td>     </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(PPOTrainer pid=18720)\u001b[0m 2022-02-24 13:25:36,959\tINFO ppo.py:250 -- In multi-agent mode, policies will be optimized sequentially by the multi-GPU optimizer. Consider setting simple_optimizer=True if this doesn't work for you.\n",
      "\u001b[2m\u001b[36m(PPOTrainer pid=18720)\u001b[0m 2022-02-24 13:25:36,959\tINFO trainer.py:792 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(PPOTrainer pid=18720)\u001b[0m 2022-02-24 13:25:36,989\tWARNING deprecation.py:46 -- DeprecationWarning: `rllib.env.remote_vector_env.RemoteVectorEnv` has been deprecated. Use `ray.rllib.env.remote_base_env.RemoteBaseEnv` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(PPOTrainer pid=18720)\u001b[0m 2022-02-24 13:25:36,990\tWARNING util.py:55 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(PPOTrainer pid=18720)\u001b[0m 2022-02-24 13:25:36,995\tWARNING deprecation.py:46 -- DeprecationWarning: `policy_mapping_fn(agent_id)` has been deprecated. Use `policy_mapping_fn(agent_id, episode, worker, **kwargs)` instead. This will raise an error in the future!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-24 13:25:40 (running for 00:00:05.96)<br>Memory usage on this node: 15.0/16.0 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/8 CPUs, 0/0 GPUs, 0.0/8.59 GiB heap, 0.0/4.29 GiB objects<br>Result logdir: /Users/bumjin/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name               </th><th>status  </th><th>loc            </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CustomEnv_cf5ce_00000</td><td>RUNNING </td><td>127.0.0.1:18720</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-24 13:25:45 (running for 00:00:10.99)<br>Memory usage on this node: 15.0/16.0 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/8 CPUs, 0/0 GPUs, 0.0/8.59 GiB heap, 0.0/4.29 GiB objects<br>Result logdir: /Users/bumjin/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name               </th><th>status  </th><th>loc            </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CustomEnv_cf5ce_00000</td><td>RUNNING </td><td>127.0.0.1:18720</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-24 13:25:50,694\tWARNING tune.py:593 -- SIGINT received (e.g. via Ctrl+C), ending Ray Tune run. This will try to checkpoint the experiment state one last time. Press CTRL+C one more time (or send SIGINT/SIGKILL/SIGTERM) to skip. \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-24 13:25:50 (running for 00:00:16.01)<br>Memory usage on this node: 15.0/16.0 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/8 CPUs, 0/0 GPUs, 0.0/8.59 GiB heap, 0.0/4.29 GiB objects<br>Result logdir: /Users/bumjin/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name               </th><th>status  </th><th>loc            </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CustomEnv_cf5ce_00000</td><td>RUNNING </td><td>127.0.0.1:18720</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-24 13:25:50 (running for 00:00:16.02)<br>Memory usage on this node: 15.0/16.0 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/8 CPUs, 0/0 GPUs, 0.0/8.59 GiB heap, 0.0/4.29 GiB objects<br>Result logdir: /Users/bumjin/ray_results/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name               </th><th>status  </th><th>loc            </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CustomEnv_cf5ce_00000</td><td>RUNNING </td><td>127.0.0.1:18720</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(PPOTrainer pid=18720)\u001b[0m 2022-02-24 13:25:50,713\tERROR worker.py:432 -- SystemExit was raised from the worker.\n",
      "\u001b[2m\u001b[36m(PPOTrainer pid=18720)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(PPOTrainer pid=18720)\u001b[0m   File \"python/ray/_raylet.pyx\", line 770, in ray._raylet.task_execution_handler\n",
      "\u001b[2m\u001b[36m(PPOTrainer pid=18720)\u001b[0m   File \"python/ray/_raylet.pyx\", line 591, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(PPOTrainer pid=18720)\u001b[0m   File \"python/ray/_raylet.pyx\", line 629, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(PPOTrainer pid=18720)\u001b[0m   File \"python/ray/_raylet.pyx\", line 636, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(PPOTrainer pid=18720)\u001b[0m   File \"python/ray/_raylet.pyx\", line 640, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(PPOTrainer pid=18720)\u001b[0m   File \"python/ray/_raylet.pyx\", line 589, in ray._raylet.execute_task.function_executor\n",
      "\u001b[2m\u001b[36m(PPOTrainer pid=18720)\u001b[0m   File \"/Users/bumjin/opt/anaconda3/envs/torch/lib/python3.6/site-packages/ray/_private/function_manager.py\", line 639, in actor_method_executor\n",
      "\u001b[2m\u001b[36m(PPOTrainer pid=18720)\u001b[0m     return method(__ray_actor, *args, **kwargs)\n",
      "\u001b[2m\u001b[36m(PPOTrainer pid=18720)\u001b[0m   File \"/Users/bumjin/opt/anaconda3/envs/torch/lib/python3.6/site-packages/ray/util/tracing/tracing_helper.py\", line 451, in _resume_span\n",
      "\u001b[2m\u001b[36m(PPOTrainer pid=18720)\u001b[0m     return method(self, *_args, **_kwargs)\n",
      "\u001b[2m\u001b[36m(PPOTrainer pid=18720)\u001b[0m   File \"/Users/bumjin/opt/anaconda3/envs/torch/lib/python3.6/site-packages/ray/tune/trainable.py\", line 315, in train\n",
      "\u001b[2m\u001b[36m(PPOTrainer pid=18720)\u001b[0m     result = self.step()\n",
      "\u001b[2m\u001b[36m(PPOTrainer pid=18720)\u001b[0m   File \"/Users/bumjin/opt/anaconda3/envs/torch/lib/python3.6/site-packages/ray/util/tracing/tracing_helper.py\", line 451, in _resume_span\n",
      "\u001b[2m\u001b[36m(PPOTrainer pid=18720)\u001b[0m     return method(self, *_args, **_kwargs)\n",
      "\u001b[2m\u001b[36m(PPOTrainer pid=18720)\u001b[0m   File \"/Users/bumjin/opt/anaconda3/envs/torch/lib/python3.6/site-packages/ray/rllib/agents/trainer.py\", line 963, in step\n",
      "\u001b[2m\u001b[36m(PPOTrainer pid=18720)\u001b[0m     step_attempt_results = self.step_attempt()\n",
      "\u001b[2m\u001b[36m(PPOTrainer pid=18720)\u001b[0m   File \"/Users/bumjin/opt/anaconda3/envs/torch/lib/python3.6/site-packages/ray/util/tracing/tracing_helper.py\", line 451, in _resume_span\n",
      "\u001b[2m\u001b[36m(PPOTrainer pid=18720)\u001b[0m     return method(self, *_args, **_kwargs)\n",
      "\u001b[2m\u001b[36m(PPOTrainer pid=18720)\u001b[0m   File \"/Users/bumjin/opt/anaconda3/envs/torch/lib/python3.6/site-packages/ray/rllib/agents/trainer.py\", line 1042, in step_attempt\n",
      "\u001b[2m\u001b[36m(PPOTrainer pid=18720)\u001b[0m     step_results = self._exec_plan_or_training_iteration_fn()\n",
      "\u001b[2m\u001b[36m(PPOTrainer pid=18720)\u001b[0m   File \"/Users/bumjin/opt/anaconda3/envs/torch/lib/python3.6/site-packages/ray/util/tracing/tracing_helper.py\", line 451, in _resume_span\n",
      "\u001b[2m\u001b[36m(PPOTrainer pid=18720)\u001b[0m     return method(self, *_args, **_kwargs)\n",
      "\u001b[2m\u001b[36m(PPOTrainer pid=18720)\u001b[0m   File \"/Users/bumjin/opt/anaconda3/envs/torch/lib/python3.6/site-packages/ray/rllib/agents/trainer.py\", line 1962, in _exec_plan_or_training_iteration_fn\n",
      "\u001b[2m\u001b[36m(PPOTrainer pid=18720)\u001b[0m     results = next(self.train_exec_impl)\n",
      "\u001b[2m\u001b[36m(PPOTrainer pid=18720)\u001b[0m   File \"/Users/bumjin/opt/anaconda3/envs/torch/lib/python3.6/site-packages/ray/util/iter.py\", line 756, in __next__\n",
      "\u001b[2m\u001b[36m(PPOTrainer pid=18720)\u001b[0m     return next(self.built_iterator)\n",
      "\u001b[2m\u001b[36m(PPOTrainer pid=18720)\u001b[0m   File \"/Users/bumjin/opt/anaconda3/envs/torch/lib/python3.6/site-packages/ray/util/iter.py\", line 783, in apply_foreach\n",
      "\u001b[2m\u001b[36m(PPOTrainer pid=18720)\u001b[0m     for item in it:\n",
      "\u001b[2m\u001b[36m(PPOTrainer pid=18720)\u001b[0m   File \"/Users/bumjin/opt/anaconda3/envs/torch/lib/python3.6/site-packages/ray/util/iter.py\", line 783, in apply_foreach\n",
      "\u001b[2m\u001b[36m(PPOTrainer pid=18720)\u001b[0m     for item in it:\n",
      "\u001b[2m\u001b[36m(PPOTrainer pid=18720)\u001b[0m   File \"/Users/bumjin/opt/anaconda3/envs/torch/lib/python3.6/site-packages/ray/util/iter.py\", line 843, in apply_filter\n",
      "\u001b[2m\u001b[36m(PPOTrainer pid=18720)\u001b[0m     for item in it:\n",
      "\u001b[2m\u001b[36m(PPOTrainer pid=18720)\u001b[0m   File \"/Users/bumjin/opt/anaconda3/envs/torch/lib/python3.6/site-packages/ray/util/iter.py\", line 843, in apply_filter\n",
      "\u001b[2m\u001b[36m(PPOTrainer pid=18720)\u001b[0m     for item in it:\n",
      "\u001b[2m\u001b[36m(PPOTrainer pid=18720)\u001b[0m   File \"/Users/bumjin/opt/anaconda3/envs/torch/lib/python3.6/site-packages/ray/util/iter.py\", line 783, in apply_foreach\n",
      "\u001b[2m\u001b[36m(PPOTrainer pid=18720)\u001b[0m     for item in it:\n",
      "\u001b[2m\u001b[36m(PPOTrainer pid=18720)\u001b[0m   File \"/Users/bumjin/opt/anaconda3/envs/torch/lib/python3.6/site-packages/ray/util/iter.py\", line 783, in apply_foreach\n",
      "\u001b[2m\u001b[36m(PPOTrainer pid=18720)\u001b[0m     for item in it:\n",
      "\u001b[2m\u001b[36m(PPOTrainer pid=18720)\u001b[0m   File \"/Users/bumjin/opt/anaconda3/envs/torch/lib/python3.6/site-packages/ray/util/iter.py\", line 791, in apply_foreach\n",
      "\u001b[2m\u001b[36m(PPOTrainer pid=18720)\u001b[0m     result = fn(item)\n",
      "\u001b[2m\u001b[36m(PPOTrainer pid=18720)\u001b[0m   File \"/Users/bumjin/opt/anaconda3/envs/torch/lib/python3.6/site-packages/ray/rllib/execution/train_ops.py\", line 339, in __call__\n",
      "\u001b[2m\u001b[36m(PPOTrainer pid=18720)\u001b[0m     buffer_index=0)\n",
      "\u001b[2m\u001b[36m(PPOTrainer pid=18720)\u001b[0m   File \"/Users/bumjin/opt/anaconda3/envs/torch/lib/python3.6/site-packages/ray/rllib/policy/torch_policy.py\", line 534, in learn_on_loaded_batch\n",
      "\u001b[2m\u001b[36m(PPOTrainer pid=18720)\u001b[0m     return self.learn_on_batch(batch)\n",
      "\u001b[2m\u001b[36m(PPOTrainer pid=18720)\u001b[0m   File \"/Users/bumjin/opt/anaconda3/envs/torch/lib/python3.6/site-packages/ray/rllib/utils/threading.py\", line 21, in wrapper\n",
      "\u001b[2m\u001b[36m(PPOTrainer pid=18720)\u001b[0m     return func(self, *a, **k)\n",
      "\u001b[2m\u001b[36m(PPOTrainer pid=18720)\u001b[0m   File \"/Users/bumjin/opt/anaconda3/envs/torch/lib/python3.6/site-packages/ray/rllib/policy/torch_policy.py\", line 434, in learn_on_batch\n",
      "\u001b[2m\u001b[36m(PPOTrainer pid=18720)\u001b[0m     grads, fetches = self.compute_gradients(postprocessed_batch)\n",
      "\u001b[2m\u001b[36m(PPOTrainer pid=18720)\u001b[0m   File \"/Users/bumjin/opt/anaconda3/envs/torch/lib/python3.6/site-packages/ray/rllib/utils/threading.py\", line 21, in wrapper\n",
      "\u001b[2m\u001b[36m(PPOTrainer pid=18720)\u001b[0m     return func(self, *a, **k)\n",
      "\u001b[2m\u001b[36m(PPOTrainer pid=18720)\u001b[0m   File \"/Users/bumjin/opt/anaconda3/envs/torch/lib/python3.6/site-packages/ray/rllib/policy/torch_policy.py\", line 606, in compute_gradients\n",
      "\u001b[2m\u001b[36m(PPOTrainer pid=18720)\u001b[0m     [postprocessed_batch])\n",
      "\u001b[2m\u001b[36m(PPOTrainer pid=18720)\u001b[0m   File \"/Users/bumjin/opt/anaconda3/envs/torch/lib/python3.6/site-packages/ray/rllib/policy/torch_policy.py\", line 1083, in _multi_gpu_parallel_grad_calc\n",
      "\u001b[2m\u001b[36m(PPOTrainer pid=18720)\u001b[0m     _worker(shard_idx, model, sample_batch, device)\n",
      "\u001b[2m\u001b[36m(PPOTrainer pid=18720)\u001b[0m   File \"/Users/bumjin/opt/anaconda3/envs/torch/lib/python3.6/site-packages/ray/rllib/policy/torch_policy.py\", line 1012, in _worker\n",
      "\u001b[2m\u001b[36m(PPOTrainer pid=18720)\u001b[0m     self._loss(self, model, self.dist_class, sample_batch))\n",
      "\u001b[2m\u001b[36m(PPOTrainer pid=18720)\u001b[0m   File \"/Users/bumjin/opt/anaconda3/envs/torch/lib/python3.6/site-packages/ray/rllib/agents/ppo/ppo_torch_policy.py\", line 104, in loss\n",
      "\u001b[2m\u001b[36m(PPOTrainer pid=18720)\u001b[0m     train_batch[SampleBatch.ACTION_DIST_INPUTS], model)\n",
      "\u001b[2m\u001b[36m(PPOTrainer pid=18720)\u001b[0m   File \"/Users/bumjin/opt/anaconda3/envs/torch/lib/python3.6/site-packages/ray/rllib/models/torch/torch_action_dist.py\", line 72, in __init__\n",
      "\u001b[2m\u001b[36m(PPOTrainer pid=18720)\u001b[0m     logits=self.inputs)\n",
      "\u001b[2m\u001b[36m(PPOTrainer pid=18720)\u001b[0m   File \"/Users/bumjin/opt/anaconda3/envs/torch/lib/python3.6/site-packages/torch/distributions/categorical.py\", line 60, in __init__\n",
      "\u001b[2m\u001b[36m(PPOTrainer pid=18720)\u001b[0m     self.logits = logits - logits.logsumexp(dim=-1, keepdim=True)\n",
      "\u001b[2m\u001b[36m(PPOTrainer pid=18720)\u001b[0m   File \"/Users/bumjin/opt/anaconda3/envs/torch/lib/python3.6/site-packages/ray/worker.py\", line 429, in sigterm_handler\n",
      "\u001b[2m\u001b[36m(PPOTrainer pid=18720)\u001b[0m     sys.exit(1)\n",
      "\u001b[2m\u001b[36m(PPOTrainer pid=18720)\u001b[0m SystemExit: 1\n",
      "\u001b[2m\u001b[36m(PPOTrainer pid=18720)\u001b[0m [2022-02-24 13:25:50,718 C 18720 4300363] core_worker.cc:499:  Check failed: _s.ok() Bad status: IOError: Broken pipe\n",
      "\u001b[2m\u001b[36m(PPOTrainer pid=18720)\u001b[0m *** StackTrace Information ***\n",
      "\u001b[2m\u001b[36m(PPOTrainer pid=18720)\u001b[0m     ray::GetCallTrace()\n",
      "\u001b[2m\u001b[36m(PPOTrainer pid=18720)\u001b[0m     ray::SpdLogMessage::Flush()\n",
      "\u001b[2m\u001b[36m(PPOTrainer pid=18720)\u001b[0m     ray::SpdLogMessage::~SpdLogMessage()\n",
      "\u001b[2m\u001b[36m(PPOTrainer pid=18720)\u001b[0m     ray::RayLog::~RayLog()\n",
      "\u001b[2m\u001b[36m(PPOTrainer pid=18720)\u001b[0m     ray::core::CoreWorker::Exit()\n",
      "\u001b[2m\u001b[36m(PPOTrainer pid=18720)\u001b[0m     ray::core::CoreWorker::ExecuteTask()\n",
      "\u001b[2m\u001b[36m(PPOTrainer pid=18720)\u001b[0m     std::__1::__function::__func<>::operator()()\n",
      "\u001b[2m\u001b[36m(PPOTrainer pid=18720)\u001b[0m     std::__1::__function::__func<>::operator()()\n",
      "\u001b[2m\u001b[36m(PPOTrainer pid=18720)\u001b[0m     ray::core::InboundRequest::Accept()\n",
      "\u001b[2m\u001b[36m(PPOTrainer pid=18720)\u001b[0m     ray::core::ActorSchedulingQueue::ScheduleRequests()\n",
      "\u001b[2m\u001b[36m(PPOTrainer pid=18720)\u001b[0m     ray::core::ActorSchedulingQueue::Add()\n",
      "\u001b[2m\u001b[36m(PPOTrainer pid=18720)\u001b[0m     ray::core::CoreWorkerDirectTaskReceiver::HandleTask()\n",
      "\u001b[2m\u001b[36m(PPOTrainer pid=18720)\u001b[0m     std::__1::__function::__func<>::operator()()\n",
      "\u001b[2m\u001b[36m(PPOTrainer pid=18720)\u001b[0m     boost::asio::detail::completion_handler<>::do_complete()\n",
      "\u001b[2m\u001b[36m(PPOTrainer pid=18720)\u001b[0m     boost::asio::detail::scheduler::do_run_one()\n",
      "\u001b[2m\u001b[36m(PPOTrainer pid=18720)\u001b[0m     boost::asio::detail::scheduler::run()\n",
      "\u001b[2m\u001b[36m(PPOTrainer pid=18720)\u001b[0m     boost::asio::io_context::run()\n",
      "\u001b[2m\u001b[36m(PPOTrainer pid=18720)\u001b[0m     ray::core::CoreWorkerProcessImpl::RunWorkerTaskExecutionLoop()\n",
      "\u001b[2m\u001b[36m(PPOTrainer pid=18720)\u001b[0m     ray::core::CoreWorkerProcess::RunTaskExecutionLoop()\n",
      "\u001b[2m\u001b[36m(PPOTrainer pid=18720)\u001b[0m     __pyx_pw_3ray_7_raylet_10CoreWorker_9run_task_loop()\n",
      "\u001b[2m\u001b[36m(PPOTrainer pid=18720)\u001b[0m     _PyCFunction_FastCallDict\n",
      "\u001b[2m\u001b[36m(PPOTrainer pid=18720)\u001b[0m     call_function\n",
      "\u001b[2m\u001b[36m(PPOTrainer pid=18720)\u001b[0m     _PyEval_EvalFrameDefault\n",
      "\u001b[2m\u001b[36m(PPOTrainer pid=18720)\u001b[0m     fast_function\n",
      "\u001b[2m\u001b[36m(PPOTrainer pid=18720)\u001b[0m     call_function\n",
      "\u001b[2m\u001b[36m(PPOTrainer pid=18720)\u001b[0m     _PyEval_EvalFrameDefault\n",
      "\u001b[2m\u001b[36m(PPOTrainer pid=18720)\u001b[0m     _PyEval_EvalCodeWithName\n",
      "\u001b[2m\u001b[36m(PPOTrainer pid=18720)\u001b[0m     PyRun_FileExFlags\n",
      "\u001b[2m\u001b[36m(PPOTrainer pid=18720)\u001b[0m     PyRun_SimpleFileExFlags\n",
      "\u001b[2m\u001b[36m(PPOTrainer pid=18720)\u001b[0m     Py_Main\n",
      "\u001b[2m\u001b[36m(PPOTrainer pid=18720)\u001b[0m     main\n",
      "\u001b[2m\u001b[36m(PPOTrainer pid=18720)\u001b[0m     start\n",
      "\u001b[2m\u001b[36m(PPOTrainer pid=18720)\u001b[0m     0x0\n",
      "\u001b[2m\u001b[36m(PPOTrainer pid=18720)\u001b[0m \n",
      "2022-02-24 13:25:50,909\tERROR tune.py:632 -- Trials did not complete: [PPO_CustomEnv_cf5ce_00000]\n",
      "2022-02-24 13:25:50,910\tINFO tune.py:636 -- Total run time: 16.23 seconds (16.01 seconds for the tuning loop).\n",
      "2022-02-24 13:25:50,910\tWARNING tune.py:641 -- Experiment has been interrupted, but the most recent state was saved. You can continue running this experiment by passing `resume=True` to `tune.run()`\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ray.tune.analysis.experiment_analysis.ExperimentAnalysis at 0x7f8c04001278>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ray.rllib.agents.dqn import DQNTrainer, DQNTorchPolicy\n",
    "from ray.rllib.agents.ppo import PPOTorchPolicy, PPOTrainer\n",
    "\n",
    "def observation_function(agent_obs, **kwargs):\n",
    "    # agents are defined here..?!\n",
    "    new_obs = {\n",
    "        \"predator_1\":np.random.random(6),\n",
    "        \"predator_2\":np.random.random(6),\n",
    "        \"prey_1\":np.random.random(6),\n",
    "        \"prey_2\":np.random.random(6),\n",
    "        \"prey_3\":np.random.random(6),\n",
    "    }\n",
    "    return new_obs\n",
    "    \n",
    "\n",
    "config = {\n",
    "    \"env\":CustomEnv,\n",
    "    \"env_config\":{},\n",
    "    \"num_workers\":0,\n",
    "    \"num_gpus\":0,\n",
    "    \"multiagent\":\n",
    "        {\"policies\":{\n",
    "            \"predator\": PolicySpec(\n",
    "                        policy_class=PPOTorchPolicy,\n",
    "                        observation_space=Box(-np.inf, np.inf, shape=(6,)),\n",
    "                        action_space=Discrete(3),\n",
    "                        config={}),\n",
    "            \"prey\": PolicySpec(\n",
    "                        policy_class=PPOTorchPolicy,\n",
    "                        observation_space=Box(-np.inf, np.inf, shape=(6,)),\n",
    "                        action_space=Discrete(3),\n",
    "                        config={}),\n",
    "            },\n",
    "         \"policy_mapping_fn\": lambda agaent_name : agaent_name.split(\"_\")[0],\n",
    "         \"policies_to_train\": ['predator', 'prey'],\n",
    "         \"observation_fn\":observation_function\n",
    "         },\n",
    "    \"framework\":\"torch\"\n",
    "}\n",
    "\n",
    "ray.tune.run(\n",
    "    \"PPO\", \n",
    "    config=config,\n",
    "    stop={\"training_iteration\":10}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "728ed223cfa85ea1ef5dcc6c79a939ffd9902707d91f95b40f547e46903ca84f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
