{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-08 11:47:21,317\tWARNING utils.py:534 -- Detecting docker specified CPUs. In previous versions of Ray, CPU detection in containers was incorrect. Please ensure that Ray has enough CPUs allocated. As a temporary workaround to revert to the prior behavior, set `RAY_USE_MULTIPROCESSING_CPU_COUNT=1` as an env var before starting Ray. Set the env var: `RAY_DISABLE_DOCKER_CPU_WARNING=1` to mute this warning.\n",
      "2022-02-08 11:47:23,782\tWARNING tune.py:570 -- Tune detects GPUs, but no trials are using GPUs. To enable trials to use GPUs, set tune.run(resources_per_trial={'gpu': 1}...) which allows Tune to expose 1 GPU to each trial. You can also override `Trainable.default_resource_request` if using the Trainable API.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-08 11:47:23 (running for 00:00:00.11)<br>Memory usage on this node: 44.3/503.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/32 CPUs, 0/2 GPUs, 0.0/53.14 GiB heap, 0.0/26.57 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/vessl/ray_results/train_2022-02-08_11-47-23<br>Number of trials: 1/1 (1 PENDING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                   </th><th>status  </th><th>loc  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_CartPole-v0_e164c_00000</td><td>PENDING </td><td>     </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-08 11:47:23,933\tERROR syncer.py:111 -- Log sync requires rsync to be installed.\n",
      "\u001b[2m\u001b[36m(ImplicitFunc pid=28887)\u001b[0m 2022-02-08 11:47:26,591\tWARNING trainer.py:1947 -- You have specified 1 evaluation workers, but your `evaluation_interval` is None! Therefore, evaluation will not occur automatically with each call to `Trainer.train()`. Instead, you will have to call `Trainer.evaluate()` manually in order to trigger an evaluation run.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-08 11:47:28 (running for 00:00:05.15)<br>Memory usage on this node: 44.6/503.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/32 CPUs, 0/2 GPUs, 0.0/53.14 GiB heap, 0.0/26.57 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/vessl/ray_results/train_2022-02-08_11-47-23<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                   </th><th>status  </th><th>loc                </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_CartPole-v0_e164c_00000</td><td>RUNNING </td><td>10.244.20.227:28887</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import the RL algorithm (Trainer) we would like to use.\n",
    "\n",
    "\n",
    "\n",
    "from custom_trainer import DeepingDQNTrainer\n",
    "\n",
    "# Configure the algorithm.\n",
    "config = {\n",
    "    # Environment (RLlib understands openAI gym registered strings).\n",
    "    \"env\": \"CartPole-v0\",\n",
    "    # Use 2 environment workers (aka \"rollout workers\") that parallelly\n",
    "    # collect samples from their own environment clone(s).\n",
    "    \"num_workers\": 2,\n",
    "    \"num_gpus\":1,\n",
    "    # Change this to \"framework: torch\", if you are using PyTorch.\n",
    "    # Also, use \"framework: tf2\" for tf2.x eager execution.\n",
    "    \"framework\": \"torch\",\n",
    "    \"train_batch_size\":32,\n",
    "    # Tweak the default model provided automatically by RLlib,\n",
    "    # given the environment's observation- and action spaces.\n",
    "    \"model\": {\n",
    "        \"fcnet_hiddens\": [64, 64],\n",
    "        \"fcnet_activation\": \"relu\",\n",
    "    },\n",
    "    # Set up a separate evaluation worker set for the\n",
    "    # `trainer.evaluate()` call after training (see below).\n",
    "    \"evaluation_num_workers\": 1,\n",
    "    # Only for evaluation runs, render the env.\n",
    "    \"exploration_config\": {\n",
    "        # The Exploration class to use.\n",
    "        \"type\": \"EpsilonGreedy\",\n",
    "        # Config for the Exploration class' constructor:\n",
    "        \"initial_epsilon\": 1.0,\n",
    "        \"final_epsilon\": 0.02,\n",
    "        \"epsilon_timesteps\": 10000, \n",
    "    },\n",
    "    \"\"\n",
    "    \"log_level\": \"DEBUG\"\n",
    "}\n",
    "\n",
    "RAY_USE_MULTIPROCESSING_CPU_COUNT=1\n",
    "def train(config, reporter):\n",
    "    # Create our RLlib Trainer.\n",
    "    trainer = DeepingDQNTrainer(config=config)\n",
    "    while True:\n",
    "        result = trainer.train()\n",
    "        reporter(**result)\n",
    "        if result['training_iteration'] > 5:\n",
    "            break \n",
    "        print(result)\n",
    "        print(\"hello\")\n",
    "\n",
    "\n",
    "# Run it for n training iterations. A training iteration includes\n",
    "# parallel sample collection by the environment workers as well as\n",
    "# loss calculation on the collected batch and a model update.\n",
    "import ray\n",
    "ray.tune.run(train, config=config, stop={\"training_iteration\": 5})\n",
    "\n",
    "# Evaluate the trained Trainer (and render each timestep to the shell's\n",
    "# output).\n",
    "# trainer.evaluate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis = ray.tune.run(\n",
    "    ppo.PPOTrainer,\n",
    "    config=config,\n",
    "    local_dir=log_dir,\n",
    "    stop=stop_criteria,\n",
    "    checkpoint_at_end=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e23575e38234af5603235627c6b85dd47126d560d85eed01b33306e63f25f1df"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
